{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Logistic Regression to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "import sklearn.svm as svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['random_tile'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-492df0b10d88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m X = df[['Discard_0', 'Discard_1', 'Discard_2', 'Discard_3', 'Discard_4', 'Discard_5', 'Discard_6',\n\u001b[1;32m----> 2\u001b[1;33m        'Discard_7', 'Discard_8', 'random_tile']]\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christoph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christoph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christoph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['random_tile'] not in index\""
     ]
    }
   ],
   "source": [
    "X = df[['Discard_0', 'Discard_1', 'Discard_2', 'Discard_3', 'Discard_4', 'Discard_5', 'Discard_6',\n",
    "       'Discard_7', 'Discard_8', 'random_tile']]\n",
    "y = df['result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "print(X.shape, y.shape)\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5705853418593212 0.003 0.01\n",
      "0.6389572060993606 0.01 0.01\n",
      "0.6576487948844073 0.1 0.01\n",
      "0.6576487948844073 1 0.01\n",
      "0.6576487948844073 10 0.01\n",
      "0.6576487948844073 100 0.01\n",
      "0.6576487948844073 1000 0.01\n",
      "0.573536645351697 0.003 0.1\n",
      "0.6409247417609444 0.01 0.1\n",
      "0.6576487948844073 0.1 0.1\n",
      "0.6576487948844073 1 0.1\n",
      "0.6576487948844073 10 0.1\n",
      "0.6576487948844073 100 0.1\n",
      "0.6576487948844073 1000 0.1\n",
      "0.5784554845056566 0.003 0.2\n",
      "0.6404328578455485 0.01 0.2\n",
      "0.6576487948844073 0.1 0.2\n",
      "0.6576487948844073 1 0.2\n",
      "0.6576487948844073 10 0.2\n",
      "0.6576487948844073 100 0.2\n",
      "0.6576487948844073 1000 0.2\n",
      "0.6010821446138711 0.003 0.5\n",
      "0.6419085095917364 0.01 0.5\n",
      "0.6576487948844073 0.1 0.5\n",
      "0.6576487948844073 1 0.5\n",
      "0.6576487948844073 10 0.5\n",
      "0.6576487948844073 100 0.5\n",
      "0.6576487948844073 1000 0.5\n",
      "0.6192818494835219 0.003 0.6\n",
      "0.6433841613379242 0.01 0.6\n",
      "0.6576487948844073 0.1 0.6\n",
      "0.6576487948844073 1 0.6\n",
      "0.6576487948844073 10 0.6\n",
      "0.6576487948844073 100 0.6\n",
      "0.6576487948844073 1000 0.6\n",
      "Best Score:  0.6576487948844073\n",
      "gamma and nu:  0.1 0.1\n"
     ]
    }
   ],
   "source": [
    "nus = [0.01, 0.1, 0.2, 0.5, 0.6]\n",
    "gs = [0.003, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "best_score, best_g, best_nu = 0,0,0\n",
    "for nu in nus:\n",
    "    for g in gs:\n",
    "        model= svm.NuSVC(nu=nu, gamma=g)\n",
    "        model.fit(X_train, y_train)\n",
    "        temp_score = model.score(X_test, y_test)\n",
    "        print(temp_score, g, nu)\n",
    "        if(temp_score > best_score):\n",
    "            best_score, best_g, best_nu = temp_score, g, c\n",
    "print(\"Best Score: \", best_score)\n",
    "print(\"gamma and nu: \", best_g, best_nu)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score, g, c\n",
      "0.6576487948844073 0.003 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 0.01 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 0.1 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 10 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 100 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1000 0.1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.661583866207575 0.003 1\n",
      "true acc:  0.06207928197456993\n",
      "false acc:  0.943904263275991\n",
      "0.6576487948844073 0.01 1\n",
      "true acc:  0.013462976813762155\n",
      "false acc:  0.9865370231862378\n",
      "0.6576487948844073 0.1 1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1 1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 10 1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 100 1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1000 1\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.5961633054599115 0.003 5\n",
      "true acc:  0.1600598354525056\n",
      "false acc:  0.7464472700074795\n",
      "0.6404328578455485 0.01 5\n",
      "true acc:  0.05609573672400898\n",
      "false acc:  0.9177262528047868\n",
      "0.6576487948844073 0.1 5\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1 5\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 10 5\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 100 5\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1000 5\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.5873093949827841 0.003 10\n",
      "true acc:  0.1824981301421092\n",
      "false acc:  0.7105459985041137\n",
      "0.6404328578455485 0.01 10\n",
      "true acc:  0.05609573672400898\n",
      "false acc:  0.9177262528047868\n",
      "0.6576487948844073 0.1 10\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1 10\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 10 10\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 100 10\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1000 10\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.5745204131824889 0.003 100\n",
      "true acc:  0.18773373223635004\n",
      "false acc:  0.6858638743455497\n",
      "0.6404328578455485 0.01 100\n",
      "true acc:  0.05609573672400898\n",
      "false acc:  0.9177262528047868\n",
      "0.6576487948844073 0.1 100\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1 100\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 10 100\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 100 100\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "0.6576487948844073 1000 100\n",
      "true acc:  0.0\n",
      "false acc:  1.0\n",
      "Best Score:  0.661583866207575\n",
      "gamma and c:  0.003 1\n"
     ]
    }
   ],
   "source": [
    "cs = [0.1, 1, 5, 10, 100]\n",
    "gs = [0.003, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "best_score, best_g, best_c = 0,0,0\n",
    "print(\"score, g, c\")\n",
    "for c in cs:\n",
    "    for g in gs:\n",
    "        model = svm.SVC(C=c, gamma=g, kernel='rbf')\n",
    "        model.fit(X_train, y_train)\n",
    "        temp_score = model.score(X_test, y_test)\n",
    "        predicted = model.predict(X_test)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(y_test, predicted).ravel()\n",
    "        print(temp_score, g, c)\n",
    "        print(\"true acc: \", (tp/(fp+tn)))\n",
    "        print(\"false acc: \", (tn/(tn+fp)))\n",
    "        if(temp_score > best_score):\n",
    "            best_score, best_g, best_c = temp_score, g, c\n",
    "print(\"Best Score: \", best_score)\n",
    "print(\"gamma and c: \", best_g, best_c)\n",
    "        \n",
    "# svcmodel = svm.SVC(C=, gamma=0.003, kernel='rbf')\n",
    "# svcmodel.fit(X_train, y_train)\n",
    "# logmodel = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "# logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn fp fn tp\n",
      "947 390 489 207\n",
      "true acc:  0.15482423335826478\n",
      "false acc:  0.7083021690351533\n",
      "0.5676340383669454\n",
      "Predicted:  {0: 1436, 1: 597}\n",
      "Data:  0    1337\n",
      "1     696\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, predicted).ravel()\n",
    "print(\"tn fp fn tp\")\n",
    "print(tn, fp, fn, tp)\n",
    "print(\"true acc: \", (tp/(fp+tn)))\n",
    "print(\"false acc: \", (tn/(tn+fp)))\n",
    "print(model.score(X_test, y_test))\n",
    "unique_p, counts_p = np.unique(predicted, return_counts=True)\n",
    "print(\"Predicted: \", dict(zip(unique_p, counts_p)))\n",
    "print(\"Data: \", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display accuracy compare with testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn fp fn tp\n",
      "1262 75 613 83\n",
      "true acc:  0.06207928197456993\n",
      "false acc:  0.943904263275991\n",
      "0.661583866207575\n",
      "Predicted:  {0: 1875, 1: 158}\n",
      "Data:  0    1337\n",
      "1     696\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# predicted = logmodel.predict(X_test)\n",
    "model = svm.SVC(C=1.0, gamma=0.003, kernel='rbf').fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, predicted).ravel()\n",
    "print(\"tn fp fn tp\")\n",
    "print(tn, fp, fn, tp)\n",
    "print(\"true acc: \", (tp/(fp+tn)))\n",
    "print(\"false acc: \", (tn/(tn+fp)))\n",
    "print(model.score(X_test, y_test))\n",
    "unique_p, counts_p = np.unique(predicted, return_counts=True)\n",
    "print(\"Predicted: \", dict(zip(unique_p, counts_p)))\n",
    "print(\"Data: \", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuaacy of Cross-Validation: 0.6534830950760155\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(SVC(C=1.0, cache_size=600), X, y, scoring='accuracy', cv=10)\n",
    "print(\"Mean Accuaacy of Cross-Validation:\" ,scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a new input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65623778 0.34376222]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([0, 8, 9, 7, 33, 18, 6, 29, 16, 20])\n",
    "columns=['Discard_0', 'Discard_1', 'Discard_2', 'Discard_3', 'Discard_4', 'Discard_5',\n",
    "         'Discard_6', 'Discard_7', 'Discard_8', 'random_tile']\n",
    "df2 = pd.DataFrame(data.reshape(-1, len(data)),columns=columns)\n",
    "print(logmodel.predict_proba(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaacy of KNN: 0.6542056074766355\n",
      "Predited 1: 143\n",
      "Predited 0: 1890\n",
      "Actual 1: 696\n",
      "Actual 0: 1337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(\"Accuaacy of KNN:\", metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "a = np.count_nonzero(predicted == 1)\n",
    "print(\"Predited 1:\",a)\n",
    "b = np.count_nonzero(predicted == 0) \n",
    "print(\"Predited 0:\", b)\n",
    "c = np.count_nonzero(y_test == 1)\n",
    "print(\"Actual 1:\", c)\n",
    "d = np.count_nonzero(y_test == 0) \n",
    "print(\"Actual 0:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual True: 696\n",
      "Predicted True: 68\n",
      "Accuracy: 0.09770114942528736\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "print(\"Actual True:\", tp+fn);\n",
    "print(\"Predicted True:\", tp);\n",
    "print(\"Accuracy:\", (tp/ (tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4428\n",
       "1    2348\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['result'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaacy of Neural Network: 0.5868175110673881\n",
      "Predited 1: 662\n",
      "Predited 0: 1371\n",
      "Actual 1: 696\n",
      "Actual 0: 1337\n",
      "Actual True: 696\n",
      "Predicted True: 259\n",
      "Accuracy: 0.37212643678160917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(110,110,110),max_iter=60000)\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "print(\"Accuaacy of Neural Network:\", metrics.accuracy_score(y_test, predictions))\n",
    "a = np.count_nonzero(predictions == 1)\n",
    "print(\"Predited 1:\",a)\n",
    "b = np.count_nonzero(predictions == 0) \n",
    "print(\"Predited 0:\", b)\n",
    "c = np.count_nonzero(y_test == 1)\n",
    "print(\"Actual 1:\", c)\n",
    "d = np.count_nonzero(y_test == 0) \n",
    "print(\"Actual 0:\", d)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"Actual True:\", tp+fn);\n",
    "print(\"Predicted True:\", tp);\n",
    "print(\"Accuracy:\", (tp / (tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
