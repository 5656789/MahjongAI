{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Logistic Regression to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Discard_0', 'Discard_1', 'Discard_2', 'Discard_3', 'Discard_4', 'Discard_5', 'Discard_6',\n",
    "       'Discard_7', 'Discard_8', 'random_tile']]\n",
    "y = df['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display accuracy compare with testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaacy of Logistic Regression: 0.6576487948844073\n",
      "Predited 1: 0\n",
      "Predited 0: 2033\n",
      "Actual 1: 696\n",
      "Actual 0: 1337\n"
     ]
    }
   ],
   "source": [
    "predicted = logmodel.predict(X_test)\n",
    "print(\"Accuaacy of Logistic Regression:\", metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "a = np.count_nonzero(predicted == 1)\n",
    "print(\"Predited 1:\",a)\n",
    "b = np.count_nonzero(predicted == 0) \n",
    "print(\"Predited 0:\", b)\n",
    "c = np.count_nonzero(y_test == 1)\n",
    "print(\"Actual 1:\", c)\n",
    "d = np.count_nonzero(y_test == 0) \n",
    "print(\"Actual 0:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual True: 696\n",
      "Predicted True: 0\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "print(\"Actual True:\", tp+fn);\n",
    "print(\"Predicted True:\", tp);\n",
    "print(\"Accuracy:\", (tp/ (tp+fn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuaacy of Cross-Validation: 0.6534830950760155\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(solver='lbfgs', multi_class='auto'), X, y, scoring='accuracy', cv=10)\n",
    "print(\"Mean Accuaacy of Cross-Validation:\" ,scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a new input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65623778 0.34376222]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([0, 8, 9, 7, 33, 18, 6, 29, 16, 20])\n",
    "columns=['Discard_0', 'Discard_1', 'Discard_2', 'Discard_3', 'Discard_4', 'Discard_5',\n",
    "         'Discard_6', 'Discard_7', 'Discard_8', 'random_tile']\n",
    "df2 = pd.DataFrame(data.reshape(-1, len(data)),columns=columns)\n",
    "print(logmodel.predict_proba(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaacy of KNN: 0.6542056074766355\n",
      "Predited 1: 143\n",
      "Predited 0: 1890\n",
      "Actual 1: 696\n",
      "Actual 0: 1337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(\"Accuaacy of KNN:\", metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "a = np.count_nonzero(predicted == 1)\n",
    "print(\"Predited 1:\",a)\n",
    "b = np.count_nonzero(predicted == 0) \n",
    "print(\"Predited 0:\", b)\n",
    "c = np.count_nonzero(y_test == 1)\n",
    "print(\"Actual 1:\", c)\n",
    "d = np.count_nonzero(y_test == 0) \n",
    "print(\"Actual 0:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual True: 696\n",
      "Predicted True: 68\n",
      "Accuracy: 0.09770114942528736\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "print(\"Actual True:\", tp+fn);\n",
    "print(\"Predicted True:\", tp);\n",
    "print(\"Accuracy:\", (tp/ (tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4428\n",
       "1    2348\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['result'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaacy of Neural Network: 0.5868175110673881\n",
      "Predited 1: 662\n",
      "Predited 0: 1371\n",
      "Actual 1: 696\n",
      "Actual 0: 1337\n",
      "Actual True: 696\n",
      "Predicted True: 259\n",
      "Accuracy: 0.37212643678160917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(110,110,110),max_iter=60000)\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "print(\"Accuaacy of Neural Network:\", metrics.accuracy_score(y_test, predictions))\n",
    "a = np.count_nonzero(predictions == 1)\n",
    "print(\"Predited 1:\",a)\n",
    "b = np.count_nonzero(predictions == 0) \n",
    "print(\"Predited 0:\", b)\n",
    "c = np.count_nonzero(y_test == 1)\n",
    "print(\"Actual 1:\", c)\n",
    "d = np.count_nonzero(y_test == 0) \n",
    "print(\"Actual 0:\", d)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"Actual True:\", tp+fn);\n",
    "print(\"Predicted True:\", tp);\n",
    "print(\"Accuracy:\", (tp / (tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
